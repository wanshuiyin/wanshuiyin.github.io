<!DOCTYPE html>
<html lang="en">


<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Ruofeng Yang's homepage.">
  <meta name="keywords" content="Ruofeng Yang, Haochen, Zhaoxiang Zhang,
                                 SJTU, CASIA,
                                 Deep Learning, Computer Vision,
                                 Segmentation, Semi-Supervised Learning, SSL, Domain Adaptation, UDA, DA">
  <meta name="author" content="Ruofeng Yang">

  <title>Ruofeng Yang (杨若峰)</title>

  <link rel="stylesheet" type="text/css" href="assets/font-awesome-4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="assets/academicons-1.8.6/css/academicons.min.css">
  <link rel="stylesheet" type="text/css" href="assets/style.css">
  <link rel="icon" type="image/png" href="assets/figures/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="assets/figures/large-icon.png">
</head>
<body data-new-gr-c-s-check-loaded="14.1014.0" data-gr-ext-installed="">


<table width="980px" align="center" border="0">
<tbody>
<tr>


<td></td>  <td valign="top">


<br>
<table style="font-size: 12pt;" width="100%" border="0">
<tbody>
  <tr>
    <td width="50%">
      <img width="250" src="./me_v2.jpg">
    </td>

    <td>
      <div class="col-xs-12 col-sm-8">
        <h1>
          <strong>Ruofeng Yang (杨若峰)</strong><br>
          <small>Shanghai Jiaotong University</small>
          </h1>
            <p><a href="https://scholar.google.com.hk/citations?user=Cw9HDacAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a> / <a href="./eaf89ad8d25bb831e14759b54b6afaf.jpg" target="_blank">RedNote</a></p>
                <p>Email: wanshuiyin[at]sjtu.edu.cn</code></p>
                <p>Wechat: yrf13618645542</code></p>
                <p>Office: Room 1119, No.1 Software Engineering Building, Dongchuan Road 800, Shanghai, China
            </div>
    </td>
  </tr>
</tbody>
</table>
<br>
<h2>About me</h2>
<p style="font-size: 12pt; text-align: justify;">
I am a 4-year PhD student in computer science in <a href="https://jhc.sjtu.edu.cn/">John Hopcroft Center,</a> <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a> under the supervision of <a href="https://shuaili8.github.io/">Prof. Shuai Li</a> since Sept. 2022.
<br> 
  My research focuses on diffusion models and reinforcement learning. Previously, I worked on the theoretical analysis of diffusion models and reinforcement learning algorithms. Currently, I am interested in integrating diffusion models with reinforcement learning, including reinforcement learning fine-tuning (RLFT) for 3D generation (IEG, Tencent Rhino-Bird Research Elite Program, 犀牛鸟精英人才计划) and video generation (美团北斗人才计划, Longcat-video base model team).
</p>
<p>
  His research focuses on computer vision and pattern recognition,
  particularly on the following topics:
  <ul>
    <li>Diffusion Models (Image, Video, Theory, Post Training)</li>
    <li>Deep Learning Theory</li>
    <li>Reinforcement Learning and RLHF</li>

  </ul>
</p>
   <p>
    <strong>He anticipates graduating in 2027 for industrial research positions!</strong> If you're interested, please feel free to reach out via email or WeChat (yrf13618645542).
  </p>
  
<br>
<h2>Research Experiences</h2>
<p style="font-size: 12pt; text-align: justify;">
  <ul>
    <li>Intern at the National University of Singapore (NUS), School of Computing, 2026/01-2026/07, Singapore.</li>
    <li>Intern at Meituan, Longcat-Video Team as a member of the 北斗人才计划.</li>
    <li>Intern at Tencent IEG, Game AI center as a member of the Tencent Rhino-Bird Research Elite Program (犀牛鸟精英人才计划), 2023, Shenzhen.</li>

  </ul>
</p>
  
<br>
<h2>News</h2>
<p style="font-size: 12pt; text-align: justify;">
  <ul>
    <li>I post a blog on the relationship between diffusion and representation learning and manifold learning <a href="./Diffusion_Representation_Manifold.html" target="_blank">[html]</a><a href="./Diffusion_Representation_Manifold.pdf" target="_blank">[pdf]</a><a href="./PPT_Diffusion_Representation_Manifold.pdf" target="_blank">[slides]</a></li>
    <li>One paper about the MoE structure of Diffusion Models is accepted by <strong>ICLR 2026</strong>!</li>
    <li>I provide a  <a href="https://github.com/wanshuiyin/OpenReview-Score-Watcher" target="_blank">Openreview plugin</a> for ICLR 2026!</li>
    <li>One paper about consistency models is accepted by <strong>ICML 2025</strong>!</li>
    <li>One paper about improved iteration complexity of VESDE (reverse SDE and PFODE) is accepted by <strong>AISTATS 2025</strong>!</li>
    <li>Two papers about the iteration complexity of diffusion models (including a training-free method) and few-shot diffusion models are accepted by <strong>NeurIPS 2024</strong>!</li>
    <li>One paper is accepted by <strong>NeurIPS 2023</strong>!</li>
    <li>One paper is accepted by <strong>ICLR 2023</strong>!</li>
    <li>One paper is accepted by <strong>AAAI 2023 (Oral)</strong>!</li>


  </ul>
</p>
  
<br>
<h2>Blogs & Tutorials & Talks</h2>
<p style="font-size: 12pt; text-align: justify;">
  <ul>
    <li>Blog on the relationship between diffusion and representation learning and manifold learning (Theory & Application)<a href="./Diffusion_Representation_Manifold.html" target="_blank">[html]</a><a href="./Diffusion_Representation_Manifold.pdf" target="_blank">[pdf]</a><a href="./Diffusion_Representation_Manifold.html" target="_blank">[html]</a><a href="./PPT_Diffusion_Representation_Manifold.pdf" target="_blank">[slides]</a></li>
    <li><a href="./A_simple_understanding_of_diffusion_model.pdf" target="_blank">A simple introduction to diffusion model (Application)</a></li>
    <li><a href="./20250810_Why RF YangR slides.pdf" target="_blank"> Why Rectified Flow is Better? Elucidating VP, VE, and RF-based diffusion models (Theory)</a></li>
    <li>A brief survey on some interesting directions about diffusion models (Theory) (Coming Soon)</li>
  </ul>
</p>
  
<br>
<h2> Publications </h2>
  As we know, diffusion models can be roughly divided into pretraining, supervised fine-tuning, RL posting training, and sampling algorithm design. My works focus on these four areas. 

  <h3> Diffusion Model MoE Structure and Pretraining </h3>
  <table cellspacing="17">
    <tbody>
      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 180px; object-fit: cover;" src="./MoLR_MoG.png">
        </td>
        <td>
          <strong>Multi-Subspace Multi-Modal Modeling for Diffusion Models: Estimation, Convergence and Mixture of Experts (ICLR 2026)</strong>
          <br><small>
          <strong>Ruofeng Yang</strong>,
          Yongcan Li (Equal Contribution),
          Bo Jiang,
          Cheng Chen,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
            [<a href="https://arxiv.org/abs/2601.01475" target="_blank">ICLR 2026</a>]
          </small>
        </td>
      </tr>
    </tbody>
  </table> 

  <h3> Diffusion Model Supervised Fine-tuning </h3>
  <table width="100%" style="border: none; border-collapse: collapse;">
    <tr>
      <td width="25%" style="vertical-align: middle; padding-right: 20px;">
        <img style="width: 100%; max-height: 180px; object-fit: cover; border-radius: 5px;" src="./CELEBA64.PNG">
      </td>
      <td style="vertical-align: middle;">
        <strong>Few-shot Diffusion Models Escape the Curse of Dimensionality (NeurIPS 2024)</strong>
        <br><br> <small>
        <strong>Ruofeng Yang</strong>,
        Bo Jiang,
        Cheng Chen,
        Ruinan Jin,
        Baoxiang Wang,
        <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
        <br>
        [<a href="./TONGAI.png" target="_blank">Best paper award (2nd Prize), TongAI 2025</a>]
        [<a href="https://neurips.cc/virtual/2024/poster/95694" target="_blank">NeurIPS 2024</a>] </small>
      </td>
    </tr>
  </table>
 <table width="100%" style="border: none; border-collapse: collapse;">
    <tr>
      <td width="25%" style="vertical-align: middle; padding-right: 20px;">
        <img style="width: 100%; max-height: 180px; object-fit: cover; border-radius: 5px;" src="./Good_pretrained.jpg">
      </td>
      <td style="vertical-align: middle;">
        <strong>Evaluating the Role of Great Pre-trained Diffusion Models in Few-shot Phase: Warm-up and Acceleration</strong>
        <br><br> <small>
        <strong>Ruofeng Yang</strong>,
        Yongcan Li (Equal Contribution)
        Bo Jiang,
        Cheng Chen,
        <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
        <br>
        [<a href="https://openreview.net/forum?id=AcTuU5Xr6r" target="_blank">Preprint</a>] </small>
      </td>
    </tr>
  </table>

  <h3> Diffusion Model Post-Training </h3>
  <table width="100%" style="border: none; border-collapse: collapse;">
    <tr>
      <td width="25%" style="vertical-align: middle; padding-right: 20px;">
        <img style="width: 100%; max-height: 180px; object-fit: cover; border-radius: 5px;" src="./MV_D3PO_C.png">
      </td>
      <td style="vertical-align: middle;">
        <strong>Contrastive guidance and feedback: A Suitable way to improve 3D Consistency of Multi-view Diffusion Model</strong>
        <br><br><small>
        <strong>Ruofeng Yang</strong>,
        Le Wan,
        Yaqing Zhang,
        <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
        <br>
        [<a href="https://openreview.net/forum?id=ZBH4fqQwJQ" target="_blank">Preprint</a>]
        </small>
      </td>
    </tr>
  </table>
  
  <h3> Diffusion Model Sampling and Condition Generation </h3>
  <table cellspacing="17">
    <tbody>
      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 180px; object-fit: cover;" src="./RF.png">
        </td>
        <td>
          <strong>Elucidating Rectified Flow with Deterministic Sampler: Polynomial Discretization Complexity for Multi and One-step Models </strong>
          <br><small>
          <strong>Ruofeng Yang</strong>,
          Zhaoyu Zhu,
          Bo Jiang,
          Cheng Chen,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
            A talk on [<a href="./20250810_Why RF YangR slides.pdf" target="_blank">CSML 2025</a>]  [<a href="https://www.arxiv.org/abs/2508.08735" target="_blank">Preprint</a>]
          </small>
        </td>
      </tr>

      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 180px; object-fit: cover;" src="./ICML_Consistency .png">
        </td>
        <td>
          <strong>Improved Discretization Complexity Analysis of Consistency Models: Variance Exploding Forward Process and Decay Discretization Scheme (ICML 2025)</strong>
          <br><small>
          <strong>Ruofeng Yang</strong>,
          Bo Jiang,
          Cheng Chen,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
            [<a href="https://openreview.net/forum?id=CZTcRSxkfe" target="_blank">ICML 2025</a>]
          </small>
        </td>
      </tr>
      
      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 360px; object-fit: cover;" src="./AISTATS.png">
        </td>
        <td>
          <strong>The Polynomial Iteration Complexity for Variance Exploding Diffusion Models: Elucidating SDE and ODE Samplers (AISTATS 2025)</strong>
          <br><small>
          <strong>Ruofeng Yang</strong>,
          Bo Jiang,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
            [<a href="https://openreview.net/forum?id=P2PdbGpzxg" target="_blank">AISTATS 2025</a>]
        </td>
      </tr>
      
      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 180px; object-fit: cover;" src="./More_example_More_figrue.png">
        </td>
        <td>
          <strong>Leveraging Drift to Improve Sample Complexity of Variance Exploding Diffusion Models (NeurIPS 2024)</strong>
          <br><small>
          <strong>Ruofeng Yang</strong>,
          Zhijie Wang,
          Bo Jiang,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
          [<a href="https://neurips.cc/virtual/2024/poster/94238#:~:text=In%20this%20work%2C%20we%20design%20a%20new%20drifted,models%20with%20reverse%20SDE%20under%20the%20manifold%20hypothesis." target="_blank">NeurIPS 2024</a>]
          </small>
        </td>
      </tr>
      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 180px; object-fit: cover;" src="./Guidance.jpg">
        </td>
        <td>
          <strong>Elucidating Guidance in Variance Exploding Diffusion Models: Fast Convergence and Better Diversity</strong>
          <br><small>
          <strong>Ruofeng Yang</strong>,
          Qiuyi Yu,
          Bo Jiang,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
          [<a href="https://openreview.net/forum?id=tWbasgJA68" target="_blank">Preprint</a>]
          </small>
        </td>
      </tr>
    </tbody>
  </table>

  <h3> Representation and Reinforcement Learning Theory </h3>
  <table cellspacing="17">
    <tbody>
      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 180px; object-fit: cover;" src="./SSL.png">
        </td>
        <td>
          <strong>Understanding Representation Learnability of Nonlinear Self-Supervised Learning (AAAI 2023 Oral)</strong>
          <br><small>
          <strong>Ruofeng Yang</strong>,
          Xiangyuan Li,
          Bo Jiang,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
          [<a href="https://github.com/wanshuiyin/AAAI-2023-The-Learnability-of-Nonlinear-SSL" target="_blank">Code</a>]
          [<a href="https://arxiv.org/abs/2401.03214#:~:text=Self-supervised%20learning%20%28SSL%29%20has%20empirically%20shown%20its%20data,the%20nonlinear%20neural%20network%20as%20a%20%60%60black%20box%22." target="_blank">AAAI 2023</a>]
          </small>
        </td>
      </tr>

      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 180px; object-fit: cover;" src="./LSUOB-REPS.png">
        </td>
        <td>
          <strong>Learning Adversarial Linear Mixture Markov Decision Processes with Bandit Feedback and Unknown Transition (ICLR 2023)</strong>
          <br><small>
          Canzhe Zhao,
          <strong>Ruofeng Yang</strong>,
          Baoxiang Wang,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
          [<a href="https://openreview.net/forum?id=sVU54nyaA9K" target="_blank">ICLR 2023</a>]
          </small>
        </td>
      </tr>

      <tr>
        <td width="25%">
          <img style="width: 100%; max-height: 180px; object-fit: cover;" src="./POLO.png">
        </td>
        <td>
          <strong>Learning Adversarial Low-rank Markov Decision Processes with Unknown Transition and Full-information Feedback (NeurIPS 2023)</strong>
          <br><small>
          Canzhe Zhao,
          <strong>Ruofeng Yang</strong>,
          Baoxiang Wang,
          Xuezhou Zhang,
          <a href="https://shuaili8.github.io/" target="_blank">Shuai Li</a>
          <br>
          [<a href="https://arxiv.org/abs/2311.07876" target="_blank">NeurIPS 2023</a>]
          </small>
        </td>
      </tr>
    </tbody>
  </table>
<br>
<h2>Professional Services</h2>
<p style="font-size: 12pt; text-align: justify;">
  Conference Reviewer for
  <ul>
    <li>International Conference on Machine Learning (ICML) 2025</li>
    <li>International Conference on Artificial Intelligence and Statistics (AISTATS) 2025</li>
    <li>International Conference on Learning Representations (ICLR) 2025</li>
    <li>Neural Information Processing Systems (NeurIPS) 2024</li>
    <li>Autonomous Agents and Multiagent Systems (AAMAS) 2022</li>
  </ul>
</p>
<br>
<h2>Rewards</h2>
<p style="font-size: 12pt; text-align: justify;">
  <ul>
    <li>National Scholarship (for Ph.D. students), from the Ministry of Education of China </li>
    <li>Shanghai Jiao Tong University Outstanding Graduates 2022 </li>
    <li>Outstanding Winner of Mathematical Contest in Modeling (top 0.1%) 2020 </li>
    <li>Tung Scholarship (Hong Kong's Tung Foundation) 2020 </li>
    <li>Yang You Scholarship 2019, 2021 </li>
  </ul>
</p>

<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=FN865ugXjN6UttwO9Eo85GxLAz0xuyV8vi357-y43ag&cl=ffffff&w=a"></script>
</td>
</tr>
</tbody>
</table>
<script type='text/javascript' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=0&t=tt&d=ZoDwnZl26icJVfh0W6PRaWJC8UIjGa9CyHu2YaqgaRI&co=ffffff&ct=ffffff&cmo=ffffff&cmn=ffffff'></script>

</body>
</html>
